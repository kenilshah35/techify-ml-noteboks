{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzrXfvwIA3Ev"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers[\"torch\"] transformers\n",
        "!pip install accelerate\n",
        "!pip install imageio\n",
        "!pip install gradio==3.47.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA45bF35wXGm"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import imageio\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "from diffusers.utils import load_image, make_image_grid\n",
        "from diffusers import StableDiffusionControlNetInpaintPipeline, ControlNetModel, UniPCMultistepScheduler\n",
        "\n",
        "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/control_v11p_sd15_inpaint\", torch_dtype=torch.float16, use_safetensors=True)\n",
        "pipe = StableDiffusionControlNetInpaintPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16, use_safetensors=True)\n",
        "pipe.scheduler =  UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_model_cpu_offload()\n",
        "\n",
        "# Function from huggingface\n",
        "# Description - Create a function to prepare the control image from the initial and mask images.\n",
        "# Thisâ€™ll create a tensor to mark the pixels in init_image as masked if the corresponding pixel in mask_image is over a certain threshold.\n",
        "def make_inpaint_condition(image, image_mask):\n",
        "    image = np.array(image.convert(\"RGB\")).astype(np.float32) / 255.0\n",
        "    image_mask = np.array(image_mask.convert(\"L\")).astype(np.float32) / 255.0\n",
        "\n",
        "    assert image.shape[0:1] == image_mask.shape[0:1]\n",
        "    image[image_mask > 0.5] = -1.0  # set as masked pixel\n",
        "    image = np.expand_dims(image, 0).transpose(0, 3, 1, 2)\n",
        "    image = torch.from_numpy(image)\n",
        "    return image\n",
        "\n",
        "def interior_generate(img,txt):\n",
        "  init_image = img['image']\n",
        "  imageio.imwrite(\"init_image.png\", init_image)\n",
        "  mask_image = img['mask']\n",
        "  imageio.imwrite(\"image_mask.png\", mask_image)\n",
        "\n",
        "  mask_image = load_image(\"./image_mask.png\")\n",
        "  init_image = load_image(\"./init_image.png\")\n",
        "\n",
        "  init_image = init_image.resize((512, 512))\n",
        "  mask_image = mask_image.resize((512, 512))\n",
        "  control_image = make_inpaint_condition(init_image, mask_image)\n",
        "\n",
        "  prompt=txt\n",
        "  negative_prompt = \"(((Ugly))), windows, doors, dining table, curtains, false ceilings, low-resolution, morbid, blurry, cropped, deformed, dehydrated, text, disfigured, duplicate, error, extra arms, extra fingers, extra legs, extra limbs, fused fingers, gross proportions, jpeg artifacts, long neck, low resolution, tiling, poorly drawn feet, extra limbs, disfigured, body out of frame, cut off, low contrast, underexposed, overexposed, bad art, beginner, amateur, distorted face, low quality, lowres, low saturation, deformed body features, watermark, water mark\"\n",
        "  output = pipe(prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image, control_image=control_image, strength=1, guidance_scale=7.5, num_inference_steps=100).images[0]\n",
        "  return init_image,output\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  with gr.Column():\n",
        "    img = gr.Image(tool=\"sketch\", label=\"base image\", show_label=True, height=512)\n",
        "    txt = gr.Textbox(label=\"prompt\", lines=2)\n",
        "    with gr.Row():\n",
        "      img1 = gr.Image(label=\"Original image\", show_label=True, height=512)\n",
        "      img2 = gr.Image(label=\"Generated image\", show_label=True, height=512)\n",
        "  btn = gr.Button()\n",
        "  btn.click(interior_generate, [img,txt], [img1,img2])\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}